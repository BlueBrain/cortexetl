{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_classes = {}\n",
    "\n",
    "# layers = {\n",
    "#     \"L1\": [1],\n",
    "#     \"L23\": [2, 3],\n",
    "#     \"L4\": [4],\n",
    "#     \"L5\": [5],\n",
    "#     \"L6\": [6],\n",
    "# }\n",
    "\n",
    "# synapse_classes = [\"EXC\", \"INH\"]\n",
    "\n",
    "# # Generate neuron classes for specific layers and synapse classes\n",
    "# for hex_ind in range(77):\n",
    "#     node_set = \"hex\" + str(hex_ind)\n",
    "#     for layer_name, layer_numbers in layers.items():\n",
    "#         for synapse_class in synapse_classes:\n",
    "            \n",
    "#             if (layer_name == 'L1') & (synapse_class == 'EXC'):\n",
    "#                 continue\n",
    "            \n",
    "#             print(f\"{layer_name}_{synapse_class}_{hex_ind}:\")\n",
    "#             print(f\"  node_set: {node_set}\")\n",
    "#             print(f\"  query:\")\n",
    "#             print(f\"    layer: {layer_numbers}\")\n",
    "#             print(f\"    synapse_class: {synapse_class}\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# synapse_classes = [\"EXC\", \"INH\"]\n",
    "\n",
    "# for hex_ind in range(77):\n",
    "#     node_set = \"hex\" + str(hex_ind)\n",
    "#     for synapse_class in synapse_classes:\n",
    "#         print(f\"ALL_{synapse_class}_{hex_ind}:\")\n",
    "#         print(f\"  node_set: {node_set}\")\n",
    "#         print(f\"  query:\")\n",
    "#         print(f\"    synapse_class: {synapse_class}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import cortexetl as c_etl\n",
    "\n",
    "ma = c_etl.analysis_initial_processing(\"5-FullCircuit-2-BetterMinis-FprScan.yaml\", loglevel=\"ERROR\")\n",
    "\n",
    "a_AllCompartments = ma.AllCompartments_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_xy_for_single_hex(hex_mean_flatspace_coords, hex_ind):\n",
    "\n",
    "#     hex_x = hex_mean_flatspace_coords.etl.q(hex=hex_ind).iloc[0]['x']\n",
    "#     hex_y = hex_mean_flatspace_coords.etl.q(hex=hex_ind).iloc[0]['y']\n",
    "\n",
    "#     return hex_x, hex_y\n",
    "\n",
    "# import pandas as pd\n",
    "# hex_mean_flatspace_coords_path = '/gpfs/bbp.cscs.ch/project/proj83/home/isbister/data/reference_data_do_not_delete/hex_mean_flatspace_coords.parquet'\n",
    "# c_etl.plot_evoked_hexes_by_hist(ma.hexes_spikes, hex_mean_flatspace_coords_path)\n",
    "\n",
    "# for hex_ind in hex_inds:\n",
    "#     hex_x, hex_y = get_xy_for_single_hex(hex_mean_flatspace_coords, hex_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 11A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import os\n",
    "import tqdm\n",
    "import cortexetl as c_etl\n",
    "from blueetl.parallel import call_by_simulation\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def make_t_bins(t_start, t_end, t_step):\n",
    "    t_bins = numpy.arange(t_start, t_end + t_step, t_step)\n",
    "    return t_bins\n",
    "\n",
    "def flatten_locations(locations, flatmap):\n",
    "    if isinstance(flatmap, list):\n",
    "        flat_locations = locations[flatmap].values\n",
    "    else:\n",
    "        from voxcell import VoxelData\n",
    "        fm = VoxelData.load_nrrd(flatmap)\n",
    "        flat_locations = fm.lookup(locations.values).astype(float)\n",
    "        flat_locations[flat_locations == -1] = numpy.NaN\n",
    "    return pandas.DataFrame(flat_locations, index=locations.index)\n",
    "\n",
    "\n",
    "def make_spatial_bins(flat_locations, nbins=1000):\n",
    "    mn = numpy.nanmin(flat_locations, axis=0)\n",
    "    mx = numpy.nanmax(flat_locations, axis=0)\n",
    "    ratio = (mx[1] - mn[1]) / (mx[0] - mn[0]) # ratio * nx ** 2 = nbins\n",
    "    nx = int(numpy.sqrt(nbins / ratio))\n",
    "    ny = int(nbins / nx)\n",
    "    binsx = numpy.linspace(mn[0], mx[0] + 1E-3, nx + 1)\n",
    "    binsy = numpy.linspace(mn[1], mx[1] + 1E-3, ny + 1)\n",
    "    return binsx, binsy\n",
    "\n",
    "def make_histogram_function(t_bins, loc_bins, location_dframe, spikes):\n",
    "    t_step = numpy.mean(numpy.diff(t_bins))\n",
    "    fac = 1000.0 / t_step\n",
    "    nrns_per_bin = numpy.histogram2d(location_dframe.values[:, 0],\n",
    "                                     location_dframe.values[:, 1],\n",
    "                                     bins=loc_bins)[0]\n",
    "    nrns_per_bin = nrns_per_bin.reshape((1,) + nrns_per_bin.shape)\n",
    "\n",
    "    spikes = spikes.loc[numpy.in1d(spikes.values, location_dframe.index.values)]\n",
    "    t = spikes.index.values\n",
    "    loc = location_dframe.loc[spikes['gid']].values\n",
    "    raw, _ = numpy.histogramdd((t, loc[:, 0], loc[:, 1]), bins=(t_bins,) + loc_bins)\n",
    "    raw = fac * raw / (nrns_per_bin + 1E-6)\n",
    "    return raw\n",
    "\n",
    "def save(hist, t_bins, loc_bins, out_root):\n",
    "    if not os.path.isdir(out_root):\n",
    "        _ = os.makedirs(out_root)\n",
    "    import h5py\n",
    "    h5 = h5py.File(os.path.join(out_root, \"spiking_activity_3d.h5\"), \"w\")\n",
    "    grp_bins = h5.create_group(\"bins\")\n",
    "    grp_bins.create_dataset(\"t\", data=t_bins)\n",
    "    grp_bins.create_dataset(\"x\", data=loc_bins[0])\n",
    "    grp_bins.create_dataset(\"y\", data=loc_bins[1])\n",
    "\n",
    "    grp_data = h5.create_group(\"histograms\")\n",
    "    for i, val in enumerate(hist.get()):\n",
    "        grp_data.create_dataset(\"instance{0}\".format(i), data=val)\n",
    "    mn_data = numpy.mean(numpy.stack(hist.get(), -1), axis=-1)\n",
    "    grp_data.create_dataset(\"mean\", data=mn_data)\n",
    "    return mn_data\n",
    "\n",
    "def setup_cmap(hist, plotting_options, hist_mean=[]):\n",
    "    \n",
    "    hist_for_mask = hist\n",
    "    if (len(hist_mean)):\n",
    "        hist_for_mask = hist_mean\n",
    "    \n",
    "    masked_hist = hist\n",
    "    mx_clim = numpy.percentile(hist, plotting_options['max_lim_pct'])\n",
    "    mn_clim = numpy.percentile(hist, plotting_options['min_lim_pct'])\n",
    "    indices_to_mask = numpy.asarray(numpy.argwhere(hist_for_mask <= plotting_options['mask_fr']))\n",
    "    for pair in indices_to_mask:\n",
    "        if (len(hist_mean)):\n",
    "            masked_hist[:, pair[0], pair[1]] = numpy.nan\n",
    "        else:\n",
    "            masked_hist[pair[0], pair[1]] = numpy.nan\n",
    "    \n",
    "    \n",
    "    cmap = plotting_options['cmap']\n",
    "    cmap.set_bad('white',1.)\n",
    "    \n",
    "    clim = [mn_clim, mx_clim]\n",
    "    \n",
    "    return cmap, clim, masked_hist\n",
    "    \n",
    "\n",
    "def plot_and_save_single_image(hist, plotting_options, path):\n",
    "\n",
    "    cmap, clim, masked_hist = setup_cmap(hist, plotting_options)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "    img = ax.imshow(masked_hist, cmap=cmap, clim=clim)\n",
    "    plt.scatter(26.50221238938053, 67.87893675169182) #hex39\n",
    "    plt.scatter(72.57363365352766, 41.2836038423319, c='r') #hex0\n",
    "    plt.colorbar(img, cmap=cmap, label='FR (spikes / s')\n",
    "    plt.box(False)\n",
    "    plt.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "import tqdm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#     plot(hist, t_bins, loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre, plotting_options, hist_mean=hist_mean)\n",
    "def plot(hist, t_bins, loc_bins, images_dir, delete_images, video_output_root, plotting_options, min_color_lim_pct=-1, hist_mean=[]):\n",
    "    \n",
    "    print(images_dir)\n",
    "    \n",
    "    if not os.path.isdir(images_dir):\n",
    "        print('oh')\n",
    "        _ = os.makedirs(images_dir)\n",
    "    \n",
    "#     print(plotting_options)\n",
    "#     print(plotting_options['max_lim_pct'])\n",
    "    cmap, clim, masked_hist = setup_cmap(hist, plotting_options, hist_mean=hist_mean)\n",
    "    \n",
    "    fps = []\n",
    "    for t_start, t_end, bin_index in tqdm.tqdm(zip(t_bins[:-1], t_bins[1:], list(range(len(t_bins))))):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "        img = ax.imshow(masked_hist[bin_index, :, :], cmap=cmap, clim=clim)\n",
    "        plt.colorbar(img, cmap=cmap, label='FR (spikes / s')\n",
    "        \n",
    "        ax.set_title(\"{0} - {1} ms\".format(t_start, t_end))\n",
    "        plt.box(False)\n",
    "        plt.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False)\n",
    "        fn = \"frame{:04d}.png\".format(bin_index)\n",
    "        fp = os.path.join(images_dir, fn)\n",
    "        fig.savefig(fp)\n",
    "        fps.append(fp)\n",
    "        if (bin_index == 0):\n",
    "            fn = \"frame{:04d}.pdf\".format(bin_index)\n",
    "            fp = os.path.join(images_dir, fn)\n",
    "            fig.savefig(fp)\n",
    "        \n",
    "        plt.close(fig)\n",
    "\n",
    "    c_etl.video_from_image_files(fps, video_output_root + \".mp4\")\n",
    "    if delete_images:\n",
    "        for f in fps:\n",
    "            os.remove(f)\n",
    "\n",
    "import numpy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "def single_flatspace_video(simulation_row, \n",
    "                           filtered_dataframes, \n",
    "                           flat_locations, \n",
    "                           flatspace_video_opt, \n",
    "                           analysis_config,\n",
    "                           plotting_options,\n",
    "                           flatspace_path_pre=None, \n",
    "                           images_dir=None):\n",
    "\n",
    "    window_row = filtered_dataframes['windows'].iloc[0]\n",
    "    \n",
    "    print(images_dir)\n",
    "\n",
    "    if (flatspace_path_pre==None):\n",
    "        flatspace_path_pre = flatspace_video_opt['video_output_root'] + str(simulation_row['simulation_id']) + \"_\" + simulation_row['simulation_string']\n",
    "    if (images_dir==None):\n",
    "        images_dir = str(window_row['flatspace_video_images_dir']) + \"/\" + flatspace_video_opt['vid_str'] + \"_\" + str(simulation_row['simulation_id']) + \"/\"\n",
    "    \n",
    "\n",
    "    t_bins = make_t_bins(window_row['t_start'], window_row['t_stop'], flatspace_video_opt['t_step'])\n",
    "    spikes = filtered_dataframes['spikes'].loc[:, ['time', 'gid']].set_index('time')\n",
    "    \n",
    "    loc_bins = make_spatial_bins(flat_locations, flatspace_video_opt['n_spatial_bins'])\n",
    "    spatial_temporal_hist = make_histogram_function(t_bins, loc_bins, flat_locations, spikes)\n",
    "    smoothed_spatial_temporal_hist = gaussian_filter(spatial_temporal_hist, [flatspace_video_opt['temporal_smoothing_sigma'], 1.0, 1.0])\n",
    "    hist = smoothed_spatial_temporal_hist\n",
    "    hist_mean = numpy.mean(hist, axis=0)\n",
    "    \n",
    "    plot(hist, t_bins, loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre + '_spont', plotting_options)\n",
    "    \n",
    "    plot_and_save_single_image(hist_mean, plotting_options, flatspace_path_pre + '_hist_mean.pdf')\n",
    "\n",
    "\n",
    "    r_dict = {\"smoothed_spatial_temporal_hist\": smoothed_spatial_temporal_hist,\n",
    "            \"t_bins\": t_bins}\n",
    "    return r_dict\n",
    "\n",
    "\n",
    "import os\n",
    "from blueetl.parallel import call_by_simulation\n",
    "from functools import partial\n",
    "\n",
    "a = a_AllCompartments\n",
    "\n",
    "for flatspace_video_key in a.analysis_config.custom['flatspace_videos']:\n",
    "    flatspace_video_opt = a.analysis_config.custom['flatspace_videos'][flatspace_video_key]\n",
    "    flatspace_video_opt['vid_str'] = flatspace_video_opt['window'] + \"_\" + str(flatspace_video_opt['t_step']) + \"_\" + str(flatspace_video_opt['n_spatial_bins']) + \"_\" + str(flatspace_video_opt['temporal_smoothing_sigma'])\n",
    "    flatspace_video_opt['video_output_root'] = str(a.figpaths.flatspace_videos) + \"/\" + flatspace_video_opt['vid_str'] + \"/\"\n",
    "    os.makedirs(flatspace_video_opt['video_output_root'], exist_ok=True)\n",
    "\n",
    "    dataframes={\n",
    "        \"circuits\": a.repo.simulations.df.loc[:, ['circuit', 'circuit_id', 'simulation_id']],\n",
    "        \"spikes\": a.repo.report.df.etl.q(neuron_class=\"ALL\", window=flatspace_video_opt['window']),\n",
    "        \"windows\": a.repo.windows.df.etl.q(window=flatspace_video_opt['window']), \n",
    "        \"neurons\": a.repo.neurons.df.etl.q(neuron_class=\"ALL\")}\n",
    "\n",
    "    gids = a.repo.neurons.df.etl.q(circuit_id=0)['gid']\n",
    "    locations = a.repo.simulations.df.loc[:, ['circuit', 'circuit_id', 'simulation_id']].iloc[0]['circuit'].nodes[None].get(gids, [\"x\", \"y\", \"z\"])\n",
    "    flat_locations = c_etl.flatten_locations(locations, a.analysis_config.custom[\"flatmap\"])\n",
    "\n",
    "    results = call_by_simulation(a.repo.simulations.df.etl.q(ca=1.05, depol_stdev_mean_ratio=0.4, desired_connected_proportion_of_invivo_frs=0.2), \n",
    "                                    dataframes, \n",
    "                                    func=partial(single_flatspace_video, \n",
    "                                                flat_locations=flat_locations, \n",
    "                                                flatspace_video_opt=flatspace_video_opt, \n",
    "                                                analysis_config=a.analysis_config.custom,\n",
    "                                                plotting_options={\"cmap\": matplotlib.cm.cividis,\n",
    "                                                                  \"mask_fr\": 0.0001,\n",
    "                                                                 \"max_lim_pct\": 99,\n",
    "                                                                 \"min_lim_pct\": 0},\n",
    "                                                flatspace_path_pre=str(a.figpaths.root) + '/' + 'Fig7D-correlated_flatspace', \n",
    "                                                images_dir=str(a.figpaths.root) + '/' + 'Fig7D-correlated_flatspace/'),\n",
    "                                    how='series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 11B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "\n",
    "from blueetl.constants import *\n",
    "from blueetl.parallel import call_by_simulation\n",
    "\n",
    "\n",
    "import cortexetl as c_etl\n",
    "\n",
    "\n",
    "\n",
    "def plot_simulation_raster(simulation_row, filtered_dataframes, analysis_config, raster_option_combination):\n",
    "        \n",
    "    plot_raster(simulation_row, \n",
    "                        filtered_dataframes['windows'].iloc[0], \n",
    "                        filtered_dataframes['spikes'], \n",
    "                        filtered_dataframes['neurons'], \n",
    "                        filtered_dataframes['neuron_classes'], \n",
    "                        raster_option_combination,\n",
    "                        analysis_config,\n",
    "                        simulation_histograms=filtered_dataframes['histograms'])\n",
    "\n",
    "\n",
    "def plot_rasters(a, custom_file_path=None, simulation_filter={}):\n",
    "\n",
    "    a.repo.simulations.df[\"SummaryPNG\"] = a.repo.simulations.df['rasters_dir'] / (a.repo.simulations.df['simulation_string'].astype(str) + \"_SUMMARY.png\")\n",
    "\n",
    "    for dict_to_unpack in a.analysis_config.custom['raster_windows']:\n",
    "\n",
    "        window_str = list(dict_to_unpack.keys())[0]\n",
    "        fig_dims = list(dict_to_unpack.values())[0]\n",
    "\n",
    "        if (type(fig_dims) == list):\n",
    "            fig_width = fig_dims[0]\n",
    "            fig_height = fig_dims[1]\n",
    "        else:\n",
    "            fig_width = fig_dims\n",
    "            fig_height = fig_width * 0.6\n",
    "        \n",
    "        raster_option_combinations = [\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=False, use_spikes=True, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES, neuron_class_groupings=c_etl.NEURON_CLASS_NO_GROUPINGS, fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=['ALL'], neuron_class_groupings=[['ALL']], extra_string='All', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES + ['ALL_EXC', 'ALL_INH'], neuron_class_groupings=c_etl.LAYER_EI_NEURON_CLASS_GROUPINGS, extra_string='LayerEI', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=5.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES + ['ALL_EXC', 'ALL_INH'], neuron_class_groupings=c_etl.LAYER_EI_NEURON_CLASS_GROUPINGS, extra_string='LayerEI', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path, lw=0.4, seperator_lw=0.2)\n",
    "                                    ]\n",
    "\n",
    "        if (a.analysis_config.custom['plot_rasters']):\n",
    "\n",
    "            print(f\"\\n----- Plot rasters, window: {window_str} -----\")\n",
    "\n",
    "            for roc in raster_option_combinations:\n",
    "\n",
    "                dataframes={\n",
    "                        \"spikes\": a.repo.report.df.etl.q(neuron_class=roc.neuron_classes, window=roc.window_str),\n",
    "                        \"windows\": a.repo.windows.df.etl.q(window=roc.window_str), \n",
    "                        \"neurons\": a.repo.neurons.df,\n",
    "                        \"neuron_classes\": a.repo.neuron_classes.df.etl.q(neuron_class=roc.neuron_classes),\n",
    "                        \"histograms\": a.features.histograms.df.etl.q(neuron_class=roc.neuron_classes, window=roc.window_str, bin_size=roc.hist_bin_size, smoothing_type=roc.smoothing_type, kernel_sd=roc.kernel_sd)\n",
    "                        }\n",
    "            \n",
    "                results = call_by_simulation(a.repo.simulations.df.etl.q(simulation_filter), \n",
    "                                                dataframes, \n",
    "                                                func=partial(plot_simulation_raster, analysis_config=a.analysis_config.custom, raster_option_combination=roc), how=\"series\")\n",
    "\n",
    "        if (a.analysis_config.custom['create_raster_videos']):\n",
    "\n",
    "            print(f\"\\n----- Create raster videos, window: {window_str} -----\")\n",
    "\n",
    "            for roc in raster_option_combinations:\n",
    "                if (a.repo.windows.df.etl.q(window=window_str).iloc[0]['window_type'] == \"spontaneous\"):\n",
    "                    for mask_key in ['', 'bursting', 'bursting_or_fr_above_threshold_or_ei_corr_r_out_of_range']:\n",
    "                        roc.create_video(a, mask_key=mask_key)\n",
    "\n",
    "                elif (a.repo.windows.df.etl.q(window=window_str).iloc[0]['window_type'] == \"evoked_stimulus_onset_zeroed\"):\n",
    "                    for mask_key_and_invert_mask_bool in [['', False], ['overly_sustained_response', False], ['overly_sustained_response', True], ['higher_secondary_peak', False], ['higher_secondary_peak', True], ['too_much_trial_to_trial_variance', False], ['too_much_trial_to_trial_variance', True], ['evoked_mask', False], ['evoked_mask', True]]:\n",
    "                        roc.create_video(a, mask_key=mask_key_and_invert_mask_bool[0], invert_mask=mask_key_and_invert_mask_bool[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RasterOptions(object):\n",
    "\n",
    "    def __init__(self, a, window_str='', neuron_group_y_axis_equal=True, use_spikes=True, smoothing_type='', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=[], neuron_class_groupings=[], extra_string='', fig_width=20, fig_height=15, custom_file_path=None, lw=0.2, seperator_lw=0.2):\n",
    "\n",
    "        self.window_str = window_str\n",
    "        self.neuron_group_y_axis_equal = neuron_group_y_axis_equal\n",
    "        self.use_spikes = use_spikes\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.hist_bin_size = hist_bin_size\n",
    "        self.kernel_sd = kernel_sd\n",
    "        self.neuron_classes = neuron_classes\n",
    "        self.neuron_class_groupings = neuron_class_groupings\n",
    "        self.extra_string = extra_string\n",
    "        self.fig_width = fig_width\n",
    "        self.fig_height = fig_height\n",
    "        self.lw = lw\n",
    "        self.seperator_lw = seperator_lw\n",
    "\n",
    "        \n",
    "        windows = pd.merge(a.repo.simulations.df.reset_index().drop([\"index\"], axis=1), a.repo.windows.df.reset_index()).set_index(['index'])\n",
    "        if (custom_file_path == None):\n",
    "            custom_file_path = windows['rasters_dir'].astype(str)\n",
    "\n",
    "        self.options_str = \"{spikes}\".format(spikes=\"S_\" if use_spikes == True else \"NS_\") + smoothing_type + \"_\" + str(hist_bin_size) + \"_\" + str(kernel_sd) + \"_\" + \"{yax}\".format(yax=\"YNE_\" if neuron_group_y_axis_equal == True else \"YE_\") + extra_string\n",
    "        self.df_file_path_key = self.options_str + '_rasters_path_png'\n",
    "        self.df_file_path_pdf_key = self.options_str + '_rasters_path_pdf'\n",
    "\n",
    "        a.repo.windows.df.loc[windows.index, self.df_file_path_key] = custom_file_path + (windows['window'].astype(str) + \"_\" + self.options_str + \"_RASTER.png\")\n",
    "        a.repo.windows.df.loc[windows.index, self.df_file_path_pdf_key] = custom_file_path+ (windows['window'].astype(str) + \"_\" + self.options_str + \"_RASTER.pdf\")\n",
    "\n",
    "\n",
    "    def create_video(self, a, mask_key='', invert_mask=False):\n",
    "\n",
    "        windows_df = a.repo.windows.df.etl.q(window=self.window_str)\n",
    "        \n",
    "        if (mask_key != ''):\n",
    "            windows_with_stats_df = pd.merge(windows_df, a.custom['custom_simulations_post_analysis'])\n",
    "            q = {mask_key: invert_mask}\n",
    "            windows_df = windows_with_stats_df.etl.q(q)\n",
    "\n",
    "        raster_videos_window_dir = str(a.figpaths.raster_videos) + \"/\" + self.window_str + \"/\" + mask_key + str(invert_mask) + \"/\"\n",
    "        os.makedirs(raster_videos_window_dir, exist_ok=True)\n",
    "\n",
    "        video_fn = raster_videos_window_dir + self.window_str + \"_\" + self.options_str + '_' + mask_key + \":\" + str(invert_mask) + \".mp4\"\n",
    "\n",
    "        c_etl.video_from_image_files(windows_df[self.df_file_path_key].astype(str).tolist(), video_fn)\n",
    "\n",
    "\n",
    "def renormalise_psth(psth):\n",
    "    new_hist = psth  - np.min(psth)\n",
    "    new_hist = new_hist / np.max(new_hist)\n",
    "    return new_hist\n",
    "\n",
    "def plot_raster(simulation_row, window_row, window_spikes, circuit_neurons, neuron_classes, raster_option_combination, analysis_config, simulation_histograms=None, spont_ei_corr_rval=-5.0):\n",
    "\n",
    "    sns.set(style=\"ticks\", context=\"paper\", font=\"Helvetica Neue\",\n",
    "        rc={\"axes.labelsize\": 7, \"legend.fontsize\": 6, \"axes.linewidth\": 0.6, \"xtick.labelsize\": 6, \"ytick.labelsize\": 6,\n",
    "            \"xtick.major.size\": 2, \"xtick.major.width\": 0.5, \"xtick.minor.size\": 1.5, \"xtick.minor.width\": 0.3,\n",
    "            \"ytick.major.size\": 2, \"ytick.major.width\": 0.5, \"ytick.minor.size\": 1.5, \"ytick.minor.width\": 0.3,\n",
    "            \"axes.titlesize\": 7, \"axes.spines.right\": False, \"axes.spines.top\": False})\n",
    "\n",
    "    start_time = time.time()\n",
    "    plt.figure(figsize=(raster_option_combination.fig_width, raster_option_combination.fig_height))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # SET NEURON CLASS COLOURS\n",
    "    neuron_classes = neuron_classes.copy()\n",
    "    neuron_classes.loc[:, 'c'] = neuron_classes.apply(lambda row : c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[row['neuron_class']][\"color\"], axis=1)\n",
    "\n",
    "    # SET NEURON CLASS START \n",
    "    if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "        neuron_classes['cum_sum'] = neuron_classes[COUNT].cumsum()\n",
    "        neuron_classes['start_pos'] = neuron_classes['cum_sum'].shift().fillna(0)\n",
    "    else:\n",
    "        neuron_classes['start_pos'] = 0\n",
    "        neuron_classes['cum_sum'] = 0\n",
    "        for neuron_class_index, neuron_class in neuron_classes.iterrows():            \n",
    "            for neuron_class_grouping_index, neuron_class_grouping in enumerate(raster_option_combination.neuron_class_groupings):\n",
    "                if neuron_class[\"neuron_class\"] in neuron_class_grouping:\n",
    "                    neuron_classes.loc[neuron_class_index, 'start_pos'] = neuron_class_grouping_index * 5000\n",
    "                    neuron_classes.loc[neuron_class_index, 'cum_sum'] = neuron_class_grouping_index * 5000 + 5000\n",
    "\n",
    "\n",
    "    # PLOT SPIKES\n",
    "    if (raster_option_combination.use_spikes):\n",
    "        window_spikes = pd.merge(neuron_classes, window_spikes)\n",
    "        window_spikes = window_spikes.set_index([CIRCUIT_ID, NEURON_CLASS, GID])\n",
    "        circuit_neurons = circuit_neurons.set_index([CIRCUIT_ID, NEURON_CLASS, GID])\n",
    "        window_spikes = circuit_neurons.join(window_spikes, how='inner')\n",
    "\n",
    "        shuffled_within_neuron_class = True\n",
    "        if (shuffled_within_neuron_class):\n",
    "            for neuron_class_index, neuron_class in neuron_classes.iterrows(): \n",
    "                nc_w_spikes = window_spikes.etl.q(neuron_class=neuron_class[NEURON_CLASS])\n",
    "                nc_random_map = np.arange(neuron_class[COUNT])\n",
    "                np.random.shuffle(nc_random_map)\n",
    "                shuffled_neuron_class_indices = nc_w_spikes.neuron_class_index.map(lambda x: nc_random_map[x])\n",
    "                neuron_scatter_pos = nc_w_spikes['start_pos'] + shuffled_neuron_class_indices\n",
    "                ax.scatter(nc_w_spikes[TIME], neuron_scatter_pos, s=0.1, c='k', linewidths=0) #, facecolors='c', s=0.2, c=nc_w_spikes['c']\n",
    "\n",
    "        else:\n",
    "            neuron_scatter_pos = window_spikes['start_pos'] + window_spikes['neuron_class_index']\n",
    "            ax.scatter(window_spikes[TIME], neuron_scatter_pos, s=0.1, c=window_spikes['c'], linewidths=0)\n",
    "\n",
    "\n",
    "\n",
    "    # OPTIONALLY LOAD INVIVO_HISTOGRAMS\n",
    "    if (window_row['window_type'] in ['evoked_stimulus_onset_zeroed', 'evoked_cortical_onset_zeroed']):\n",
    "        vivo_df = pd.read_feather(analysis_config['vivo_df']).reset_index()\n",
    "        vivo_neuron_classes = vivo_df[\"neuron_class\"].unique()\n",
    "\n",
    "    # PLOT DIVIDERS AND HISTOGRAMS\n",
    "    for neuron_class_index, neuron_class in neuron_classes.iterrows():\n",
    "        plt.plot([window_row['t_start'], window_row['t_stop']], [neuron_class['start_pos'], neuron_class['start_pos']], lw=raster_option_combination.seperator_lw, c='k')\n",
    "\n",
    "        if (simulation_histograms is not None):\n",
    "\n",
    "            bin_indices, hist_array = c_etl.hist_elements(simulation_histograms.etl.q(simulation_id=window_row[SIMULATION_ID], \n",
    "                                                                                        neuron_class=neuron_class[NEURON_CLASS], \n",
    "                                                                                        window=raster_option_combination.window_str, \n",
    "                                                                                        bin_size=raster_option_combination.hist_bin_size, \n",
    "                                                                                        smoothing_type=raster_option_combination.smoothing_type, \n",
    "                                                                                        kernel_sd=raster_option_combination.kernel_sd))\n",
    "\n",
    "\n",
    "            if (hist_array.shape[0] != 0):\n",
    "                hist_max = np.max(hist_array)\n",
    "                if (hist_max != 0.0):\n",
    "                    max_normalised_hist = hist_array / np.max(hist_array)\n",
    "\n",
    "                    if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "                        plt.plot(window_row['t_start'] + (bin_indices * raster_option_combination.hist_bin_size), neuron_class['cum_sum'] - neuron_class[COUNT]*max_normalised_hist, c=neuron_class['c'], lw=raster_option_combination.lw)\n",
    "                    else:\n",
    "                        plt.plot(window_row['t_start'] + (bin_indices * raster_option_combination.hist_bin_size), neuron_class['cum_sum'] - 5000*(max_normalised_hist), c=neuron_class['c'], lw=raster_option_combination.lw)\n",
    "\n",
    "                    if (window_row['window_type'] in ['evoked_stimulus_onset_zeroed', 'evoked_cortical_onset_zeroed']):\n",
    "                        if (neuron_class[NEURON_CLASS] in list(c_etl.vivo_neuron_class_map.keys())):\n",
    "                            in_vivo_neuron_class = c_etl.vivo_neuron_class_map[neuron_class[NEURON_CLASS]]\n",
    "                            if in_vivo_neuron_class in vivo_neuron_classes:\n",
    "                                nc_data = vivo_df[(vivo_df[\"neuron_class\"] == in_vivo_neuron_class) & (vivo_df[\"barrel\"] == \"C2\")].iloc[0]\n",
    "                                nc_mean = nc_data[\"psth_mean\"]\n",
    "                                # nc_sd = nc_data[\"psth_sd\"]\n",
    "\n",
    "                                x = window_row['t_start'] - 50.0 + (1.0 * np.asarray(range(len(nc_mean))))\n",
    "\n",
    "                                if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "                                    y = neuron_class['cum_sum'] - neuron_class[COUNT]*nc_mean\n",
    "                                else:\n",
    "                                    y = neuron_class['cum_sum'] - 5000*(nc_mean)\n",
    "\n",
    "\n",
    "                                plt.plot(x, y, c=neuron_class['c'], lw=raster_option_combination.lw, linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # PLOT OPTIONS AND SAVE\n",
    "    x_tick_distance = 5\n",
    "    duration = window_row['t_stop'] - window_row['t_start']\n",
    "    if (duration > 100):\n",
    "        x_tick_distance = 100\n",
    "    if (duration > 1000):\n",
    "        x_tick_distance = 1000\n",
    "\n",
    "    ax.set_yticks(neuron_classes['start_pos'] + (neuron_classes[COUNT]/2.0), minor=False)\n",
    "    if (raster_option_combination.use_spikes):\n",
    "        ax.set_yticklabels([c_etl.neuron_class_label_map[nc] for nc in neuron_classes['neuron_class']], minor=False)\n",
    "    else:\n",
    "        ax.set_yticks(neuron_classes['start_pos'] + (5000.0/2.0), minor=False)\n",
    "#         print([nc_str.split('_')[0] for nc_str in neuron_classes['neuron_class']])\n",
    "        ax.set_yticklabels([nc_str.split('_')[0] for nc_str in neuron_classes['neuron_class']], minor=False)\n",
    "\n",
    "    ax.set_xlim([window_row['t_start'], window_row['t_stop']])\n",
    "    ax.set_ylim([0, neuron_classes['cum_sum'].max()])\n",
    "    ax.set_ylabel('')\n",
    "    # ax.set_xlabel('Time from window start (ms)')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_axisbelow(True)\n",
    "    title_str = str(simulation_row['simulation_id']) + \" \" + simulation_row['simulation_string'] #+ \"    \" + raster_option_combination.options_str\n",
    "    if (spont_ei_corr_rval != -5.0):\n",
    "        title_str += \"  spont_ei_corr_rval: \" + str(np.around(spont_ei_corr_rval, decimals=3))\n",
    "    ax.set_title(title_str)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_distance))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_distance))\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.savefig(window_row[raster_option_combination.df_file_path_key], bbox_inches='tight')\n",
    "    plt.savefig(window_row[raster_option_combination.df_file_path_pdf_key], bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Raster generated: \", \"{:.2f}\".format(time.time() - start_time), 's')\n",
    "\n",
    "\n",
    "ma.hex0_spikes.analysis_config.custom['plot_rasters'] = True\n",
    "ma.hex59_spikes.analysis_config.custom['plot_rasters'] = True\n",
    "    \n",
    "ma.hex0_spikes.analysis_config.custom['raster_windows'][0]['conn_spont'] = [2.5, 2.13]\n",
    "ma.hex59_spikes.analysis_config.custom['raster_windows'][0]['conn_spont'] = [2.5, 2.13]\n",
    "# print(ma.hex0_spikes.repo.simulations.df.etl.q(desired_connected_proportion_of_invivo_frs=0.15))\n",
    "# print(ma.hex0_spikes.repo.spikes.df.etl.q(desired_connected_proportion_of_invivo_frs=0.15))\n",
    "plot_rasters(ma.hex0_spikes, custom_file_path=str(a.figpaths.root) + '/' + 'Fig11B-Hex0', simulation_filter={\"simulation_id\":3})\n",
    "plot_rasters(ma.hex59_spikes, custom_file_path=str(a.figpaths.root) + '/' + 'Fig11B-Hex59', simulation_filter={\"ca\":1.05, \"depol_stdev_mean_ratio\": 0.4, \"desired_connected_proportion_of_invivo_frs\": 0.15})\n",
    "# c_etl.plot_rasters(a_hex0, custom_file_path='figures/Fig7A-HexX', simulation_filter={\"ca\":1.1, \"depol_stdev_mean_ratio\": 0.2, \"desired_connected_proportion_of_invivo_frs\": 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_etl.multi_hex_analysis(a_AllCompartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evoked_hexes_by_hist(a, hex_mean_flatspace_coords):\n",
    "\n",
    "    hists_for_plot = a.features.histograms.df.etl.q(window=\"evoked_SOZ_100ms\", bin_size=1.0, smoothing_type='Gaussian', kernel_sd=1.0).reset_index()\n",
    "    for simulation_id in hists_for_plot.simulation_id.unique():\n",
    "        simulation_hists = hists_for_plot.etl.q(simulation_id=simulation_id)\n",
    "        plot_evoked_hists_by_hex(a, simulation_id, simulation_hists, list(range(0, 77)), hex_mean_flatspace_coords, 0)\n",
    "\n",
    "import pandas as pd\n",
    "hex_mean_flatspace_coords_path = '/gpfs/bbp.cscs.ch/project/proj83/home/isbister/data/reference_data_do_not_delete/hex_mean_flatspace_coords.parquet'\n",
    "hex_mean_flatspace_coords = pd.read_parquet(hex_mean_flatspace_coords_path)\n",
    "c_etl.plot_evoked_hexes_by_hist(ma.hexes_spikes, hex_mean_flatspace_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikewarp3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
