{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "import cortexetl as c_etl\n",
    "\n",
    "ma = c_etl.analysis_initial_processing(\"3-ThalamicStimuli-MegaScan2Scalings.yaml\", loglevel=\"ERROR\")\n",
    "a_hex0 = ma.hex0_spikes\n",
    "a_hexO1 = ma.hex_O1_spikes\n",
    "c_etl.post_analysis(a_hex0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sparsity\n",
    "a_hex0.features.by_gid_and_trial.df['did_spike'] = a_hex0.features.by_gid_and_trial.df['count'].astype(bool)\n",
    "means_by_neuron_class = a_hex0.features.by_gid_and_trial.df.groupby(['simulation_id', 'window', 'neuron_class']).mean().reset_index()\n",
    "\n",
    "neuron_classes, vivo_df, rp_psth_df, svo_psth_df = c_etl.evoked_processing(a_hex0)\n",
    "\n",
    "silico_bin_size=0.5; silico_sigma=2\n",
    "nc_stat_and_mask_df = a_hex0.custom['sim_mask'] #.etl.q(bin_size=silico_bin_size, sigma=silico_sigma)\n",
    "\n",
    "means_by_neuron_class = pd.merge(means_by_neuron_class, nc_stat_and_mask_df.drop(['window'], axis=1), on=['simulation_id']) # , 'neuron_class'\n",
    "means_by_neuron_class = means_by_neuron_class.etl.q(vpm_l5e_cond_scaling_factor=1.36, window='evoked_SOZ_100ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_etl.evoked_ratios_line_plot(a_hex0, neuron_classes)\n",
    "# c_etl.evoked_heatmaps(a_hex0)\n",
    "# c_etl.compare_time_courses(a_hex0, vivo_df, silico_bin_size=0.5, silico_sigma=2)\n",
    "c_etl.psth_plots(a_hex0, neuron_classes, rp_psth_df, svo_psth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import blueetl as etl\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import sys\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import os\n",
    "import cortexetl as c_etl\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def layer_and_pairwise_sparsity_comparison(nc_stat_and_mask_df, decay, nc_pairs, path, xlim, xticks, figsize=(1.64, 1.64), xlabel=\"Time (ms)\"):\n",
    "\n",
    "    flattened_ncs = [item for sublist in nc_pairs for item in sublist]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for simulation_id in nc_stat_and_mask_df.simulation_id.unique():\n",
    "        for nc_pair in nc_pairs:\n",
    "            cs = [c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[0]]['color'], c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[1]]['color']]\n",
    "            q_df = nc_stat_and_mask_df.etl.q(simulation_id=simulation_id, neuron_class=nc_pair, SimBad100p50p25pDecayOverlySustained=False)\n",
    "#             q_df = nc_stat_and_mask_df.etl.q(simulation_id=simulation_id, neuron_class=nc_pair)\n",
    "            if len(q_df):\n",
    "                x_to_plot =[q_df.etl.q(neuron_class=nc_pair[0]).iloc[0][decay], q_df.etl.q(neuron_class=nc_pair[1]).iloc[0][decay]]\n",
    "                y_to_plot = [flattened_ncs.index(nc_pair[0]) + 1, flattened_ncs.index(nc_pair[1]) + 1]\n",
    "                plt.plot(x_to_plot, y_to_plot, c='grey', lw=.2)\n",
    "                plt.scatter(x_to_plot, y_to_plot, c=cs, s=0.2)\n",
    "\n",
    "#     for nc_pair in nc_pairs:\n",
    "#         cs = [c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[0]]['color'], c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[1]]['color']]\n",
    "#         nc_pair_df = vivo_df.etl.q(neuron_class=nc_pair, bin_size=1.0, sigma=1, experiment=vivo_exp)\n",
    "#         if (len(nc_pair_df)):\n",
    "#             x_to_plot = [nc_pair_df.etl.q(neuron_class=nc_pair[0]).iloc[0][decay], nc_pair_df.etl.q(neuron_class=nc_pair[1]).iloc[0][decay]]\n",
    "#             y_to_plot = [flattened_ncs.index(nc_pair[0]) + 1, flattened_ncs.index(nc_pair[1]) + 1]\n",
    "#             plt.plot(x_to_plot, y_to_plot, c='k', lw=1.0)\n",
    "#             plt.scatter(x_to_plot, y_to_plot, c=cs, s=1.3)\n",
    "\n",
    "    plt.gca().set_xlabel(xlabel)\n",
    "    plt.gca().set_xlim(xlim)\n",
    "    plt.gca().set_xticks(ticks=xticks)\n",
    "    plt.gca().set_yticks(ticks=np.arange(len(flattened_ncs)) + 1,labels=[c_etl.neuron_class_label_map[nc] for nc in flattened_ncs])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    \n",
    "layer_and_pairwise_sparsity_comparison(means_by_neuron_class, 'did_spike', [[\"L6_INH\", \"L6_EXC\"], [\"L5_INH\", \"L5_EXC\"], [\"L4_INH\", \"L4_EXC\"], [\"L23_INH\", \"L23_EXC\"]], str(a_hex0.figpaths.root) + '/' + \"sparsity.pdf\", [0.0, 0.4], [0.0, 0.1, 0.2, 0.3, 0.4], figsize=(2, 3), xlabel='Proportion of\\nspiking cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_dims = (a_hex0.analysis_config.custom['heatmap_dims']['hor_key'], \n",
    "           a_hex0.analysis_config.custom['heatmap_dims']['ver_key'], \n",
    "           a_hex0.analysis_config.custom['heatmap_dims']['x_key'], \n",
    "           a_hex0.analysis_config.custom['heatmap_dims']['y_key'])\n",
    "\n",
    "\n",
    "# means_by_neuron_class.etl.q(neuron_class='ALL')\n",
    "\n",
    "c_etl.heatmap(means_by_neuron_class.etl.q(neuron_class='ALL'), \n",
    "              \"did_spike\", \n",
    "              str(a_hex0.figpaths.root) + '/' + \"sparsity_heatmap\", \n",
    "              *hm_dims, \n",
    "              mask_key=\"SimBad100p50p25pDecayOverlySustained\", \n",
    "              figsize=(6, 4.5),\n",
    "             override_cmap='cividis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = a_hex0.features.by_gid_and_trial.df.etl.q(neuron_class='ALL', window='evoked_SOZ_100ms')\n",
    "\n",
    "\n",
    "# print(a_hex0.features.by_gid_and_trial.df.etl.q(neuron_class='ALL', window='evoked_SOZ_100ms')['count'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['didnt_spike'] = filtered_df['count'] == 0\n",
    "filtered_df['spiked_only_once'] = filtered_df['count'] == 1\n",
    "filtered_df['spiked_more_than_once'] = filtered_df['count'] > 1\n",
    "filtered_df['spiked_atleast_once'] = filtered_df['count'] >= 1\n",
    "counts_filtered_df = filtered_df.groupby(['simulation_id']).sum()\n",
    "counts_filtered_df['proportion_spiking_only_once'] = counts_filtered_df['spiked_only_once'] / counts_filtered_df['spiked_atleast_once']\n",
    "\n",
    "counts_filtered_df = pd.merge(counts_filtered_df, nc_stat_and_mask_df.drop(['window'], axis=1), on=['simulation_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_etl.heatmap(counts_filtered_df, \n",
    "              \"proportion_spiking_only_once\", \n",
    "              str(a_hex0.figpaths.root) + '/' + \"proportion_spiking_only_once_heatmap\", \n",
    "              *hm_dims, \n",
    "              mask_key=\"SimBad100p50p25pDecayOverlySustained\", \n",
    "              figsize=(6, 4.5),\n",
    "             override_cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True, reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hex0.analysis_config.custom['plot_rasters'] = True\n",
    "a_hex0.analysis_config.custom['raster_windows'][1]['half_stim_period'] = [2.5, 2.5]\n",
    "\n",
    "c_etl.plot_rasters(a_hex0, custom_file_path=str(a_hex0.figpaths.root) + '/', simulation_filter={\"ca\":1.05, \"depol_stdev_mean_ratio\": 0.4, \"desired_connected_proportion_of_invivo_frs\": 0.3, \"vpm_pct\":10.0, \"vpm_l5e_cond_scaling_factor\":1.36})\n",
    "# c_etl.plot_rasters(a_hex0, custom_file_path='figures/Fig7A-Sim2', simulation_filter={\"ca\":1.1, \"depol_stdev_mean_ratio\": 0.2, \"desired_connected_proportion_of_invivo_frs\": 0.9})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raster video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "\n",
    "from blueetl.constants import *\n",
    "from blueetl.parallel import call_by_simulation\n",
    "\n",
    "import cortexetl as c_etl\n",
    "\n",
    "def plot_simulation_raster(simulation_row, filtered_dataframes, analysis_config, raster_option_combination):\n",
    "        \n",
    "    plot_raster(simulation_row, \n",
    "                        filtered_dataframes['windows'].iloc[0], \n",
    "                        filtered_dataframes['spikes'], \n",
    "                        filtered_dataframes['neurons'], \n",
    "                        filtered_dataframes['neuron_classes'], \n",
    "                        raster_option_combination,\n",
    "                        analysis_config,\n",
    "                        simulation_histograms=filtered_dataframes['histograms'])\n",
    "\n",
    "\n",
    "def plot_rasters(a, custom_file_path=None, simulation_filter={}):\n",
    "\n",
    "    a.repo.simulations.df[\"SummaryPNG\"] = a.repo.simulations.df['rasters_dir'] / (a.repo.simulations.df['simulation_string'].astype(str) + \"_SUMMARY.png\")\n",
    "\n",
    "    for dict_to_unpack in a.analysis_config.custom['raster_windows']:\n",
    "\n",
    "        window_str = list(dict_to_unpack.keys())[0]\n",
    "        fig_dims = list(dict_to_unpack.values())[0]\n",
    "\n",
    "        if (type(fig_dims) == list):\n",
    "            fig_width = fig_dims[0]\n",
    "            fig_height = fig_dims[1]\n",
    "        else:\n",
    "            fig_width = fig_dims\n",
    "            fig_height = fig_width * 0.6\n",
    "        \n",
    "        raster_option_combinations = [\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=False, use_spikes=True, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES, neuron_class_groupings=c_etl.NEURON_CLASS_NO_GROUPINGS, fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=['ALL'], neuron_class_groupings=[['ALL']], extra_string='All', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES + ['ALL_EXC', 'ALL_INH'], neuron_class_groupings=c_etl.LAYER_EI_NEURON_CLASS_GROUPINGS, extra_string='LayerEI', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path),\n",
    "                                    RasterOptions(a, window_str=window_str, neuron_group_y_axis_equal=True, use_spikes=False, smoothing_type='Gaussian', hist_bin_size=5.0, kernel_sd=1.0, neuron_classes=c_etl.LAYER_EI_NEURON_CLASSES + ['ALL_EXC', 'ALL_INH'], neuron_class_groupings=c_etl.LAYER_EI_NEURON_CLASS_GROUPINGS, extra_string='LayerEI', fig_width=fig_width, fig_height=fig_height, custom_file_path=custom_file_path, lw=0.4, seperator_lw=0.2)\n",
    "                                    ]\n",
    "\n",
    "        if (a.analysis_config.custom['plot_rasters']):\n",
    "\n",
    "            print(f\"\\n----- Plot rasters, window: {window_str} -----\")\n",
    "\n",
    "            for roc in raster_option_combinations:\n",
    "\n",
    "                dataframes={\n",
    "                        \"spikes\": a.repo.report.df.etl.q(neuron_class=roc.neuron_classes, window=roc.window_str, trial=0),\n",
    "                        \"windows\": a.repo.windows.df.etl.q(window=roc.window_str), \n",
    "                        \"neurons\": a.repo.neurons.df,\n",
    "                        \"neuron_classes\": a.repo.neuron_classes.df.etl.q(neuron_class=roc.neuron_classes),\n",
    "                        \"histograms\": a.features.histograms.df.etl.q(neuron_class=roc.neuron_classes, window=roc.window_str, bin_size=roc.hist_bin_size, smoothing_type=roc.smoothing_type, kernel_sd=roc.kernel_sd)\n",
    "                        }\n",
    "            \n",
    "                results = call_by_simulation(a.repo.simulations.df.etl.q(simulation_filter), \n",
    "                                                dataframes, \n",
    "                                                func=partial(plot_simulation_raster, analysis_config=a.analysis_config.custom, raster_option_combination=roc), how=\"series\")\n",
    "\n",
    "        if (a.analysis_config.custom['create_raster_videos']):\n",
    "\n",
    "            print(f\"\\n----- Create raster videos, window: {window_str} -----\")\n",
    "\n",
    "            for roc in raster_option_combinations:\n",
    "                if (a.repo.windows.df.etl.q(window=window_str).iloc[0]['window_type'] == \"spontaneous\"):\n",
    "                    for mask_key in ['', 'bursting', 'bursting_or_fr_above_threshold_or_ei_corr_r_out_of_range']:\n",
    "                        roc.create_video(a, mask_key=mask_key)\n",
    "\n",
    "                elif (a.repo.windows.df.etl.q(window=window_str).iloc[0]['window_type'] == \"evoked_stimulus_onset_zeroed\"):\n",
    "                    for mask_key_and_invert_mask_bool in [['', False], ['overly_sustained_response', False], ['overly_sustained_response', True], ['higher_secondary_peak', False], ['higher_secondary_peak', True], ['too_much_trial_to_trial_variance', False], ['too_much_trial_to_trial_variance', True], ['evoked_mask', False], ['evoked_mask', True]]:\n",
    "                        roc.create_video(a, mask_key=mask_key_and_invert_mask_bool[0], invert_mask=mask_key_and_invert_mask_bool[1])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RasterOptions(object):\n",
    "\n",
    "    def __init__(self, a, window_str='', neuron_group_y_axis_equal=True, use_spikes=True, smoothing_type='', hist_bin_size=3.0, kernel_sd=1.0, neuron_classes=[], neuron_class_groupings=[], extra_string='', fig_width=20, fig_height=15, custom_file_path=None, lw=0.2, seperator_lw=0.2):\n",
    "\n",
    "        self.window_str = window_str\n",
    "        self.neuron_group_y_axis_equal = neuron_group_y_axis_equal\n",
    "        self.use_spikes = use_spikes\n",
    "        self.smoothing_type = smoothing_type\n",
    "        self.hist_bin_size = hist_bin_size\n",
    "        self.kernel_sd = kernel_sd\n",
    "        self.neuron_classes = neuron_classes\n",
    "        self.neuron_class_groupings = neuron_class_groupings\n",
    "        self.extra_string = extra_string\n",
    "        self.fig_width = fig_width\n",
    "        self.fig_height = fig_height\n",
    "        self.lw = lw\n",
    "        self.seperator_lw = seperator_lw\n",
    "\n",
    "        \n",
    "        windows = pd.merge(a.repo.simulations.df.reset_index().drop([\"index\"], axis=1), a.repo.windows.df.reset_index()).set_index(['index'])\n",
    "        if (custom_file_path == None):\n",
    "            custom_file_path = windows['rasters_dir'].astype(str)\n",
    "\n",
    "        self.options_str = \"{spikes}\".format(spikes=\"S_\" if use_spikes == True else \"NS_\") + smoothing_type + \"_\" + str(hist_bin_size) + \"_\" + str(kernel_sd) + \"_\" + \"{yax}\".format(yax=\"YNE_\" if neuron_group_y_axis_equal == True else \"YE_\") + extra_string\n",
    "        self.df_file_path_key = self.options_str + '_rasters_path_png'\n",
    "        self.df_file_path_pdf_key = self.options_str + '_rasters_path_pdf'\n",
    "\n",
    "        a.repo.windows.df.loc[windows.index, self.df_file_path_key] = custom_file_path + (windows['window'].astype(str) + \"_\" + self.options_str + \"_RASTER.png\")\n",
    "        a.repo.windows.df.loc[windows.index, self.df_file_path_pdf_key] = custom_file_path+ (windows['window'].astype(str) + \"_\" + self.options_str + \"_RASTER.pdf\")\n",
    "\n",
    "\n",
    "    def create_video(self, a, mask_key='', invert_mask=False):\n",
    "\n",
    "        windows_df = a.repo.windows.df.etl.q(window=self.window_str)\n",
    "        \n",
    "        if (mask_key != ''):\n",
    "            windows_with_stats_df = pd.merge(windows_df, a.custom['custom_simulations_post_analysis'])\n",
    "            q = {mask_key: invert_mask}\n",
    "            windows_df = windows_with_stats_df.etl.q(q)\n",
    "\n",
    "        raster_videos_window_dir = str(a.figpaths.raster_videos) + \"/\" + self.window_str + \"/\" + mask_key + str(invert_mask) + \"/\"\n",
    "        os.makedirs(raster_videos_window_dir, exist_ok=True)\n",
    "\n",
    "        video_fn = raster_videos_window_dir + self.window_str + \"_\" + self.options_str + '_' + mask_key + \":\" + str(invert_mask) + \".mp4\"\n",
    "\n",
    "        c_etl.video_from_image_files(windows_df[self.df_file_path_key].astype(str).tolist(), video_fn)\n",
    "\n",
    "\n",
    "def renormalise_psth(psth):\n",
    "    new_hist = psth  - np.min(psth)\n",
    "    new_hist = new_hist / np.max(new_hist)\n",
    "    return new_hist\n",
    "\n",
    "def plot_raster(simulation_row, window_row, window_spikes, circuit_neurons, neuron_classes, raster_option_combination, analysis_config, simulation_histograms=None, spont_ei_corr_rval=-5.0):\n",
    "\n",
    "    sns.set(style=\"ticks\", context=\"paper\", font=\"Helvetica Neue\",\n",
    "        rc={\"axes.labelsize\": 7, \"legend.fontsize\": 6, \"axes.linewidth\": 0.6, \"xtick.labelsize\": 6, \"ytick.labelsize\": 6,\n",
    "            \"xtick.major.size\": 2, \"xtick.major.width\": 0.5, \"xtick.minor.size\": 1.5, \"xtick.minor.width\": 0.3,\n",
    "            \"ytick.major.size\": 2, \"ytick.major.width\": 0.5, \"ytick.minor.size\": 1.5, \"ytick.minor.width\": 0.3,\n",
    "            \"axes.titlesize\": 7, \"axes.spines.right\": False, \"axes.spines.top\": False})\n",
    "\n",
    "    start_time = time.time()\n",
    "    plt.figure(figsize=(raster_option_combination.fig_width, raster_option_combination.fig_height))\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # SET NEURON CLASS COLOURS\n",
    "    neuron_classes = neuron_classes.copy()\n",
    "    neuron_classes.loc[:, 'c'] = neuron_classes.apply(lambda row : c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[row['neuron_class']][\"color\"], axis=1)\n",
    "\n",
    "    # SET NEURON CLASS START \n",
    "    if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "        neuron_classes['cum_sum'] = neuron_classes[COUNT].cumsum()\n",
    "        neuron_classes['start_pos'] = neuron_classes['cum_sum'].shift().fillna(0)\n",
    "    else:\n",
    "        neuron_classes['start_pos'] = 0\n",
    "        neuron_classes['cum_sum'] = 0\n",
    "        for neuron_class_index, neuron_class in neuron_classes.iterrows():            \n",
    "            for neuron_class_grouping_index, neuron_class_grouping in enumerate(raster_option_combination.neuron_class_groupings):\n",
    "                if neuron_class[\"neuron_class\"] in neuron_class_grouping:\n",
    "                    neuron_classes.loc[neuron_class_index, 'start_pos'] = neuron_class_grouping_index * 5000\n",
    "                    neuron_classes.loc[neuron_class_index, 'cum_sum'] = neuron_class_grouping_index * 5000 + 5000\n",
    "\n",
    "\n",
    "    # PLOT SPIKES\n",
    "    if (raster_option_combination.use_spikes):\n",
    "        window_spikes = pd.merge(neuron_classes, window_spikes)\n",
    "        window_spikes = window_spikes.set_index([CIRCUIT_ID, NEURON_CLASS, GID])\n",
    "        circuit_neurons = circuit_neurons.set_index([CIRCUIT_ID, NEURON_CLASS, GID])\n",
    "        window_spikes = circuit_neurons.join(window_spikes, how='inner')\n",
    "\n",
    "        shuffled_within_neuron_class = True\n",
    "        if (shuffled_within_neuron_class):\n",
    "            for neuron_class_index, neuron_class in neuron_classes.iterrows(): \n",
    "                nc_w_spikes = window_spikes.etl.q(neuron_class=neuron_class[NEURON_CLASS])\n",
    "                nc_random_map = np.arange(neuron_class[COUNT])\n",
    "                np.random.shuffle(nc_random_map)\n",
    "                shuffled_neuron_class_indices = nc_w_spikes.neuron_class_index.map(lambda x: nc_random_map[x])\n",
    "                neuron_scatter_pos = nc_w_spikes['start_pos'] + shuffled_neuron_class_indices\n",
    "                ax.scatter(nc_w_spikes[TIME], neuron_scatter_pos, s=0.1, c=nc_w_spikes['c'], linewidths=0) #, facecolors='c', s=0.2\n",
    "\n",
    "        else:\n",
    "            neuron_scatter_pos = window_spikes['start_pos'] + window_spikes['neuron_class_index']\n",
    "            ax.scatter(window_spikes[TIME], neuron_scatter_pos, s=0.1, c=window_spikes['c'], linewidths=0)\n",
    "\n",
    "\n",
    "\n",
    "    # OPTIONALLY LOAD INVIVO_HISTOGRAMS\n",
    "    if (window_row['window_type'] in ['evoked_stimulus_onset_zeroed', 'evoked_cortical_onset_zeroed']):\n",
    "        vivo_df = pd.read_feather(analysis_config['vivo_df']).reset_index()\n",
    "        vivo_neuron_classes = vivo_df[\"neuron_class\"].unique()\n",
    "\n",
    "    # PLOT DIVIDERS AND HISTOGRAMS\n",
    "    for neuron_class_index, neuron_class in neuron_classes.iterrows():\n",
    "        plt.plot([window_row['t_start'], window_row['t_stop']], [neuron_class['start_pos'], neuron_class['start_pos']], lw=raster_option_combination.seperator_lw, c='k')\n",
    "\n",
    "        if (simulation_histograms is not None):\n",
    "\n",
    "            bin_indices, hist_array = c_etl.hist_elements(simulation_histograms.etl.q(simulation_id=window_row[SIMULATION_ID], \n",
    "                                                                                        neuron_class=neuron_class[NEURON_CLASS], \n",
    "                                                                                        window=raster_option_combination.window_str, \n",
    "                                                                                        bin_size=raster_option_combination.hist_bin_size, \n",
    "                                                                                        smoothing_type=raster_option_combination.smoothing_type, \n",
    "                                                                                        kernel_sd=raster_option_combination.kernel_sd))\n",
    "\n",
    "\n",
    "            if (hist_array.shape[0] != 0):\n",
    "                hist_max = np.max(hist_array)\n",
    "                if (hist_max != 0.0):\n",
    "                    max_normalised_hist = hist_array / np.max(hist_array)\n",
    "\n",
    "                    if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "                        plt.plot(window_row['t_start'] + (bin_indices * raster_option_combination.hist_bin_size), neuron_class['cum_sum'] - neuron_class[COUNT]*max_normalised_hist, c=neuron_class['c'], lw=raster_option_combination.lw)\n",
    "                    else:\n",
    "                        plt.plot(window_row['t_start'] + (bin_indices * raster_option_combination.hist_bin_size), neuron_class['cum_sum'] - 5000*(max_normalised_hist), c=neuron_class['c'], lw=raster_option_combination.lw)\n",
    "\n",
    "                    if (window_row['window_type'] in ['evoked_stimulus_onset_zeroed', 'evoked_cortical_onset_zeroed']):\n",
    "                        if (neuron_class[NEURON_CLASS] in list(c_etl.vivo_neuron_class_map.keys())):\n",
    "                            in_vivo_neuron_class = c_etl.vivo_neuron_class_map[neuron_class[NEURON_CLASS]]\n",
    "                            if in_vivo_neuron_class in vivo_neuron_classes:\n",
    "                                nc_data = vivo_df[(vivo_df[\"neuron_class\"] == in_vivo_neuron_class) & (vivo_df[\"barrel\"] == \"C2\")].iloc[0]\n",
    "                                nc_mean = nc_data[\"psth_mean\"]\n",
    "                                # nc_sd = nc_data[\"psth_sd\"]\n",
    "\n",
    "                                x = window_row['t_start'] - 50.0 + (1.0 * np.asarray(range(len(nc_mean))))\n",
    "\n",
    "                                if (not raster_option_combination.neuron_group_y_axis_equal):\n",
    "                                    y = neuron_class['cum_sum'] - neuron_class[COUNT]*nc_mean\n",
    "                                else:\n",
    "                                    y = neuron_class['cum_sum'] - 5000*(nc_mean)\n",
    "\n",
    "\n",
    "                                plt.plot(x, y, c=neuron_class['c'], lw=raster_option_combination.lw, linestyle='--')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # PLOT OPTIONS AND SAVE\n",
    "    x_tick_distance = 5\n",
    "    duration = window_row['t_stop'] - window_row['t_start']\n",
    "    if (duration > 50):\n",
    "        x_tick_distance = 10\n",
    "    if (duration > 100):\n",
    "        x_tick_distance = 100\n",
    "    if (duration > 1000):\n",
    "        x_tick_distance = 1000\n",
    "\n",
    "    ax.set_yticks(neuron_classes['start_pos'] + (neuron_classes[COUNT]/2.0), minor=False)\n",
    "    if (raster_option_combination.use_spikes):\n",
    "        ax.set_yticklabels([c_etl.neuron_class_label_map[nc] for nc in neuron_classes['neuron_class']], minor=False)\n",
    "    else:\n",
    "        ax.set_yticks(neuron_classes['start_pos'] + (5000.0/2.0), minor=False)\n",
    "#         print([nc_str.split('_')[0] for nc_str in neuron_classes['neuron_class']])\n",
    "        ax.set_yticklabels([nc_str.split('_')[0] for nc_str in neuron_classes['neuron_class']], minor=False)\n",
    "\n",
    "    ax.set_xlim([window_row['t_start'], window_row['t_stop']])\n",
    "    ax.set_ylim([0, neuron_classes['cum_sum'].max()])\n",
    "    ax.set_ylabel('')\n",
    "    # ax.set_xlabel('Time from window start (ms)')\n",
    "    ax.set_xlabel('Time (ms)')\n",
    "    ax.set_axisbelow(True)\n",
    "    title_str = str(simulation_row['simulation_id']) + \" \" + simulation_row['simulation_string'] #+ \"    \" + raster_option_combination.options_str\n",
    "    if (spont_ei_corr_rval != -5.0):\n",
    "        title_str += \"  spont_ei_corr_rval: \" + str(np.around(spont_ei_corr_rval, decimals=3))\n",
    "    ax.set_title(title_str)\n",
    "\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(x_tick_distance))\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(x_tick_distance))\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    plt.savefig(window_row[raster_option_combination.df_file_path_key], bbox_inches='tight', dpi=600)\n",
    "    plt.savefig(window_row[raster_option_combination.df_file_path_pdf_key], bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Raster generated: \", \"{:.2f}\".format(time.time() - start_time), 's')\n",
    "\n",
    "plot_rasters(a_hex0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a_hexO1\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import os\n",
    "import tqdm\n",
    "import cortexetl as c_etl\n",
    "from blueetl.parallel import call_by_simulation\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def make_t_bins(t_start, t_end, t_step):\n",
    "    t_bins = numpy.arange(t_start, t_end + t_step, t_step)\n",
    "    return t_bins\n",
    "\n",
    "def flatten_locations(locations, flatmap):\n",
    "    if isinstance(flatmap, list):\n",
    "        flat_locations = locations[flatmap].values\n",
    "    else:\n",
    "        from voxcell import VoxelData\n",
    "        fm = VoxelData.load_nrrd(flatmap)\n",
    "        flat_locations = fm.lookup(locations.values).astype(float)\n",
    "        flat_locations[flat_locations == -1] = numpy.NaN\n",
    "    return pandas.DataFrame(flat_locations, index=locations.index)\n",
    "\n",
    "\n",
    "def make_spatial_bins(flat_locations, nbins=1000):\n",
    "    mn = numpy.nanmin(flat_locations, axis=0)\n",
    "    mx = numpy.nanmax(flat_locations, axis=0)\n",
    "    ratio = (mx[1] - mn[1]) / (mx[0] - mn[0]) # ratio * nx ** 2 = nbins\n",
    "    nx = int(numpy.sqrt(nbins / ratio))\n",
    "    ny = int(nbins / nx)\n",
    "    binsx = numpy.linspace(mn[0], mx[0] + 1E-3, nx + 1)\n",
    "    binsy = numpy.linspace(mn[1], mx[1] + 1E-3, ny + 1)\n",
    "    return binsx, binsy\n",
    "\n",
    "def make_histogram_function(t_bins, loc_bins, location_dframe, spikes):\n",
    "    t_step = numpy.mean(numpy.diff(t_bins))\n",
    "    fac = 1000.0 / t_step\n",
    "    nrns_per_bin = numpy.histogram2d(location_dframe.values[:, 0],\n",
    "                                     location_dframe.values[:, 1],\n",
    "                                     bins=loc_bins)[0]\n",
    "    nrns_per_bin = nrns_per_bin.reshape((1,) + nrns_per_bin.shape)\n",
    "\n",
    "    spikes = spikes.loc[numpy.in1d(spikes.values, location_dframe.index.values)]\n",
    "    t = spikes.index.values\n",
    "    loc = location_dframe.loc[spikes['gid']].values\n",
    "    raw, _ = numpy.histogramdd((t, loc[:, 0], loc[:, 1]), bins=(t_bins,) + loc_bins)\n",
    "    raw = fac * raw / (nrns_per_bin + 1E-6)\n",
    "    return raw\n",
    "\n",
    "def save(hist, t_bins, loc_bins, out_root):\n",
    "    if not os.path.isdir(out_root):\n",
    "        _ = os.makedirs(out_root)\n",
    "    import h5py\n",
    "    h5 = h5py.File(os.path.join(out_root, \"spiking_activity_3d.h5\"), \"w\")\n",
    "    grp_bins = h5.create_group(\"bins\")\n",
    "    grp_bins.create_dataset(\"t\", data=t_bins)\n",
    "    grp_bins.create_dataset(\"x\", data=loc_bins[0])\n",
    "    grp_bins.create_dataset(\"y\", data=loc_bins[1])\n",
    "\n",
    "    grp_data = h5.create_group(\"histograms\")\n",
    "    for i, val in enumerate(hist.get()):\n",
    "        grp_data.create_dataset(\"instance{0}\".format(i), data=val)\n",
    "    mn_data = numpy.mean(numpy.stack(hist.get(), -1), axis=-1)\n",
    "    grp_data.create_dataset(\"mean\", data=mn_data)\n",
    "    return mn_data\n",
    "\n",
    "def setup_cmap(hist, plotting_options, hist_mean=[]):\n",
    "    \n",
    "    hist_for_mask = hist\n",
    "    if (len(hist_mean)):\n",
    "        hist_for_mask = hist_mean\n",
    "    \n",
    "    masked_hist = hist\n",
    "    mx_clim = numpy.percentile(hist, plotting_options['max_lim_pct'])\n",
    "    mn_clim = numpy.percentile(hist, plotting_options['min_lim_pct'])\n",
    "    indices_to_mask = numpy.asarray(numpy.argwhere(hist_for_mask <= plotting_options['mask_fr']))\n",
    "    for pair in indices_to_mask:\n",
    "        if (len(hist_mean)):\n",
    "            masked_hist[:, pair[0], pair[1]] = numpy.nan\n",
    "        else:\n",
    "            masked_hist[pair[0], pair[1]] = numpy.nan\n",
    "    \n",
    "    \n",
    "    cmap = plotting_options['cmap']\n",
    "    cmap.set_bad('white',1.)\n",
    "    \n",
    "    clim = [mn_clim, mx_clim]\n",
    "    \n",
    "    return cmap, clim, masked_hist\n",
    "    \n",
    "\n",
    "def plot_and_save_single_image(hist, plotting_options, path):\n",
    "\n",
    "    cmap, clim, masked_hist = setup_cmap(hist, plotting_options)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "    img = ax.imshow(masked_hist, cmap=cmap, clim=clim)\n",
    "    plt.colorbar(img, cmap=cmap, label='FR (spikes / s')\n",
    "    plt.box(False)\n",
    "    plt.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy\n",
    "import tqdm\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#     plot(hist, t_bins, loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre, plotting_options, hist_mean=hist_mean)\n",
    "def plot(hist, t_bins, loc_bins, images_dir, delete_images, video_output_root, plotting_options, min_color_lim_pct=-1, hist_mean=[]):\n",
    "    \n",
    "    if not os.path.isdir(images_dir):\n",
    "        _ = os.makedirs(images_dir)\n",
    "    \n",
    "    cmap, clim, masked_hist = setup_cmap(hist, plotting_options, hist_mean=hist_mean)\n",
    "    \n",
    "    fps = []\n",
    "    for t_start, t_end, bin_index in tqdm.tqdm(zip(t_bins[:-1], t_bins[1:], list(range(len(t_bins))))):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_axes([0.05, 0.05, 0.9, 0.9])\n",
    "        img = ax.imshow(masked_hist[bin_index, :, :], cmap=cmap, clim=clim)\n",
    "        plt.colorbar(img, cmap=cmap, label='FR (spikes / s')\n",
    "        \n",
    "        ax.set_title(\"{0} - {1} ms\".format(t_start, t_end))\n",
    "        plt.box(False)\n",
    "        plt.tick_params(left = False, right = False, labelleft = False, labelbottom = False, bottom = False)\n",
    "        fn = \"frame{:04d}.png\".format(bin_index)\n",
    "        fp = os.path.join(images_dir, fn)\n",
    "        fig.savefig(fp)\n",
    "        fps.append(fp)\n",
    "        if (bin_index == 0):\n",
    "            fn = \"frame{:04d}.pdf\".format(bin_index)\n",
    "            fp = os.path.join(images_dir, fn)\n",
    "            fig.savefig(fp)\n",
    "        \n",
    "        plt.close(fig)\n",
    "    \n",
    "    print(video_output_root)\n",
    "    c_etl.video_from_image_files(fps, video_output_root + \".mp4\")\n",
    "    if delete_images:\n",
    "        for f in fps:\n",
    "            os.remove(f)\n",
    "\n",
    "import numpy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "def single_flatspace_video(simulation_row, \n",
    "                           filtered_dataframes, \n",
    "                           flat_locations, \n",
    "                           flatspace_video_opt, \n",
    "                           analysis_config,\n",
    "                           plotting_options,\n",
    "                           flatspace_path_pre=None, \n",
    "                           images_dir=None):\n",
    "\n",
    "    window_row = filtered_dataframes['windows'].iloc[0]\n",
    "\n",
    "    if (flatspace_path_pre==None):\n",
    "        flatspace_path_pre = flatspace_video_opt['video_output_root'] + str(simulation_row['simulation_id']) + \"_\" + simulation_row['simulation_string']\n",
    "    if (images_dir==None):\n",
    "        images_dir = str(window_row['flatspace_video_images_dir']) + \"/\" + flatspace_video_opt['vid_str'] + \"_\" + str(simulation_row['simulation_id']) + \"/\"\n",
    "    \n",
    "\n",
    "    t_bins = make_t_bins(window_row['t_start'], window_row['t_stop'], flatspace_video_opt['t_step'])\n",
    "    spikes = filtered_dataframes['spikes'].loc[:, ['time', 'gid']].set_index('time')\n",
    "    \n",
    "    loc_bins = make_spatial_bins(flat_locations, flatspace_video_opt['n_spatial_bins'])\n",
    "    spatial_temporal_hist = make_histogram_function(t_bins, loc_bins, flat_locations, spikes)\n",
    "    smoothed_spatial_temporal_hist = gaussian_filter(spatial_temporal_hist, [flatspace_video_opt['temporal_smoothing_sigma'], 1.0, 1.0])\n",
    "    hist = smoothed_spatial_temporal_hist\n",
    "    hist_mean = numpy.mean(hist, axis=0)\n",
    "    \n",
    "    plot(hist, t_bins, loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre, plotting_options, hist_mean=hist_mean)\n",
    "    plot_and_save_single_image(hist_mean, plotting_options, flatspace_path_pre + '_hist_mean.pdf')\n",
    "\n",
    "    print(flatspace_video_opt)\n",
    "    \n",
    "    if (flatspace_video_opt['stim_anal'] != None):\n",
    "        \n",
    "#         print(\"Hey\")\n",
    "\n",
    "        where_stim = numpy.argwhere(numpy.logical_and(((t_bins) >= flatspace_video_opt['stim_anal']['stim_period'][0]), ((t_bins)) < flatspace_video_opt['stim_anal']['stim_period'][1])).flatten()\n",
    "        where_not_stim = numpy.argwhere(numpy.logical_and(((t_bins) >= flatspace_video_opt['stim_anal']['spont_period'][0]), ((t_bins)) < flatspace_video_opt['stim_anal']['spont_period'][1])).flatten()\n",
    "\n",
    "        hist_stim = hist[where_stim[:-1]]\n",
    "        hist_not_stim = hist[where_not_stim[:-1]]\n",
    "        hist_stim_mean = numpy.mean(hist_stim, axis=0)\n",
    "        hist_not_stim_mean = numpy.mean(hist_not_stim, axis=0)\n",
    "\n",
    "        hist_stim_mean_diff = hist_stim_mean - hist_not_stim_mean\n",
    "        log_hist_stim_mean_diff = numpy.log(hist_stim_mean_diff)\n",
    "\n",
    "        stim_minus_spont = hist_stim - hist_not_stim_mean\n",
    "\n",
    "        plot(stim_minus_spont, t_bins[where_stim], loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre + '_stim_minus_spont', plotting_options)\n",
    "        plot(stim_minus_spont, t_bins[where_stim], loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre + '_stim_minus_spont_min_lim_60', plotting_options, min_color_lim_pct=60)\n",
    "        # plot(stim_minus_spont, t_bins[where_stim], loc_bins, images_dir, flatspace_video_opt['delete_images'], flatspace_path_pre + '_stim_minus_spont_min_lim_60_log', min_color_lim_pct=60)\n",
    "        # plot(numpy.log(hist_stim - hist_not_stim_mean), t_bins[where_stim], loc_bins, images_dir, flatspace_path_pre + 'log_subtrac_mean')\n",
    "\n",
    "        plot_and_save_single_image(hist_not_stim_mean, plotting_options, flatspace_path_pre + '_hist_not_stim_mean.pdf')\n",
    "        plot_and_save_single_image(hist_stim_mean, plotting_options, flatspace_path_pre + '_hist_stim_mean.pdf')\n",
    "        plot_and_save_single_image(hist_stim_mean_diff, plotting_options, flatspace_path_pre + '_hist_stim_mean_diff.pdf')\n",
    "        plot_and_save_single_image(log_hist_stim_mean_diff, plotting_options, flatspace_path_pre + '_log_hist_stim_mean_diff.pdf')\n",
    "        plot_and_save_single_image(log_hist_stim_mean_diff, plotting_options, flatspace_path_pre + '_log_hist_stim_mean_diff_-4_-2.pdf')\n",
    "\n",
    "\n",
    "    r_dict = {\"smoothed_spatial_temporal_hist\": smoothed_spatial_temporal_hist,\n",
    "            \"t_bins\": t_bins}\n",
    "    return r_dict\n",
    "\n",
    "\n",
    "import os\n",
    "from blueetl.parallel import call_by_simulation\n",
    "from functools import partial\n",
    "\n",
    "for flatspace_video_key in a.analysis_config.custom['flatspace_videos']:\n",
    "    flatspace_video_opt = a.analysis_config.custom['flatspace_videos'][flatspace_video_key]\n",
    "    flatspace_video_opt['vid_str'] = flatspace_video_opt['window'] + \"_\" + str(flatspace_video_opt['t_step']) + \"_\" + str(flatspace_video_opt['n_spatial_bins']) + \"_\" + str(flatspace_video_opt['temporal_smoothing_sigma'])\n",
    "    flatspace_video_opt['video_output_root'] = str(a.figpaths.flatspace_videos) + \"/\" + flatspace_video_opt['vid_str'] + \"/\"\n",
    "    os.makedirs(flatspace_video_opt['video_output_root'], exist_ok=True)\n",
    "\n",
    "    dataframes={\n",
    "        \"circuits\": a.repo.simulations.df.loc[:, ['circuit', 'circuit_id', 'simulation_id']],\n",
    "        \"spikes\": a.repo.report.df.etl.q(neuron_class=\"ALL\", window=flatspace_video_opt['window']),\n",
    "        \"windows\": a.repo.windows.df.etl.q(window=flatspace_video_opt['window']), \n",
    "        \"neurons\": a.repo.neurons.df.etl.q(neuron_class=\"ALL\")}\n",
    "\n",
    "    gids = a.repo.neurons.df.etl.q(circuit_id=0)['gid']\n",
    "    locations = a.repo.simulations.df.loc[:, ['circuit', 'circuit_id', 'simulation_id']].iloc[0]['circuit'].nodes[None].get(gids, [\"x\", \"y\", \"z\"])\n",
    "#     print(locations)\n",
    "    \n",
    "    \n",
    "#     print(a.analysis_config.custom[\"flatmap\"])\n",
    "    flat_locations = c_etl.flatten_locations(locations, a.analysis_config.custom[\"flatmap\"])\n",
    "\n",
    "    results = call_by_simulation(a.repo.simulations.df.etl.q(ca=1.1, depol_stdev_mean_ratio=0.4, desired_connected_proportion_of_invivo_frs=0.3, vpm_pct=10.0, vpm_l5e_cond_scaling_factor=1.36), \n",
    "                                    dataframes, \n",
    "                                    func=partial(single_flatspace_video, \n",
    "                                                flat_locations=flat_locations, \n",
    "                                                flatspace_video_opt=flatspace_video_opt, \n",
    "                                                analysis_config=a.analysis_config.custom,\n",
    "                                                plotting_options={\"cmap\": matplotlib.cm.cividis,\n",
    "                                                                  \"mask_fr\": 0.5,\n",
    "                                                                 \"max_lim_pct\": 99,\n",
    "                                                                 \"min_lim_pct\": 0},\n",
    "                                                flatspace_path_pre=str(a_hex0.figpaths.root) + '/Fig7D-correlated_flatspace', \n",
    "                                                images_dir=str(a_hex0.figpaths.root) + '/' + 'Fig7D-correlated_flatspace/'),\n",
    "                                    how='series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron_classes, vivo_df, rp_psth_df, svo_psth_df = c_etl.evoked_processing(a_hex0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fig 7C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import blueetl as etl\n",
    "from scipy.interpolate import interp1d\n",
    "import seaborn as sns\n",
    "from matplotlib import cm\n",
    "import sys\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import os\n",
    "import cortexetl as c_etl\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def layer_and_pairwise_comparison(nc_stat_and_mask_df, vivo_df, vivo_exp, decay, nc_pairs, path, xlim, xticks, figsize=(1.64, 1.64)):\n",
    "\n",
    "    flattened_ncs = [item for sublist in nc_pairs for item in sublist]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for simulation_id in nc_stat_and_mask_df.simulation_id.unique():\n",
    "        for nc_pair in nc_pairs:\n",
    "            cs = [c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[0]]['color'], c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[1]]['color']]\n",
    "            q_df = nc_stat_and_mask_df.etl.q(simulation_id=simulation_id, neuron_class=nc_pair, SimBad100p50p25pDecayOverlySustained=False)\n",
    "            if len(q_df):\n",
    "                x_to_plot =[q_df.etl.q(neuron_class=nc_pair[0]).iloc[0][decay] + np.random.normal(0.0, 0.04, 1), q_df.etl.q(neuron_class=nc_pair[1]).iloc[0][decay] + np.random.normal(0.0, 0.04, 1)]\n",
    "                y_to_plot = [flattened_ncs.index(nc_pair[0]) + 1, flattened_ncs.index(nc_pair[1]) + 1]\n",
    "                plt.plot(x_to_plot, y_to_plot, c='grey', lw=.2)\n",
    "                plt.scatter(x_to_plot, y_to_plot, c=cs, s=0.2)\n",
    "\n",
    "    for nc_pair in nc_pairs:\n",
    "        cs = [c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[0]]['color'], c_etl.NEURON_CLASS_LAYERS_AND_SYNAPSE_CLASSES[nc_pair[1]]['color']]\n",
    "        nc_pair_df = vivo_df.etl.q(neuron_class=nc_pair, bin_size=1.0, sigma=1, experiment=vivo_exp)\n",
    "        if (len(nc_pair_df)):\n",
    "            x_to_plot = [nc_pair_df.etl.q(neuron_class=nc_pair[0]).iloc[0][decay], nc_pair_df.etl.q(neuron_class=nc_pair[1]).iloc[0][decay]]\n",
    "            y_to_plot = [flattened_ncs.index(nc_pair[0]) + 1, flattened_ncs.index(nc_pair[1]) + 1]\n",
    "            plt.plot(x_to_plot, y_to_plot, c='k', lw=1.0)\n",
    "            plt.scatter(x_to_plot, y_to_plot, c=cs, s=1.3)\n",
    "\n",
    "    plt.gca().set_xlabel(\"Time (ms)\")\n",
    "    plt.gca().set_xlim(xlim)\n",
    "    plt.gca().set_xticks(ticks=xticks)\n",
    "    plt.gca().set_yticks(ticks=np.arange(len(flattened_ncs)) + 1,labels=[c_etl.neuron_class_label_map[nc] for nc in flattened_ncs])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# print(a_hex0.custom.keys())\n",
    "\n",
    "# print(a_hex0.custom['window_timepoints_comp_w_mask'])\n",
    "\n",
    "\n",
    "a = a_hex0\n",
    "silico_bin_size=0.5\n",
    "silico_sigma=2\n",
    "    \n",
    "# nc_stat_and_mask_df = a.custom['nc_window_stat_and_mask_df'].etl.q(bin_size=silico_bin_size, sigma=silico_sigma)\n",
    "\n",
    "nc_stat_and_mask_df = a_hex0.custom['window_timepoints_comp_w_mask'].etl.q(bin_size=silico_bin_size, sigma=silico_sigma)\n",
    "figs_dir = custom_file_path=str(a_hex0.figpaths.root) + '/'\n",
    "decay = '1.0'\n",
    "    \n",
    "nc_stat_and_mask_df['layer'] = nc_stat_and_mask_df.apply(lambda row: row['neuron_class'].split('_')[0], axis = 1)\n",
    "\n",
    "layer_and_pairwise_comparison(nc_stat_and_mask_df, vivo_df, \"ReyesPuerta\", decay, [[\"L6_INH\", \"L6_EXC\"], [\"L5_INH\", \"L5_EXC\"], [\"L4_INH\", \"L4_EXC\"], [\"L23_INH\", \"L23_EXC\"]], figs_dir + \"ReyesPuertaEI_latencies.pdf\", [3.5, 11], [4.0, 6.0, 8.0, 10.0], figsize=(1.15, 1.5))\n",
    "layer_and_pairwise_comparison(nc_stat_and_mask_df, vivo_df, \"YuSvoboda\", decay, [[\"L6_PV\", \"L6_SST\"], [\"L5_PV\", \"L5_SST\"], [\"L4_PV\", \"L4_SST\"], [\"L23_PV\", \"L23_SST\"]], figs_dir + \"ReyesPuertaPVSST_latencies.pdf\", [3.5, 18.5], [4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0], figsize=(1.75, 1.5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_etl.evoked_ratios_analaysis(a, neuron_classes)\n",
    "#     create_heatmaps(a)\n",
    "#     psth_plots(a, neuron_classes, rp_psth_df, svo_psth_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikewarp3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
